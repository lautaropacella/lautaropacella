### **Hello! My name is Lautaro Nicolás Pacella. My background is in scientific research in the field of psychology. I'm currently finishing the Msc in Data Science and Society from Tilburg Univesity. Here you will be able to see some of my personal projects:**

## Personal Projects
### [PhD Twitter Bot](https://twitter.com/PhDsBOT1)
* Automatization of a bot that web-scraps a page in search for PhD's offers in the field of Machine Learning and Artificial Intelligence and twits them every day.

### [Tango Generator](https://share.streamlit.io/lautaropacella/tango-generator/main/tango_generator.py)
* Automatic tango lyrics generator based on the architecture of GPT-2 model.
* Web-Scraping for almost 4000 tango lyrics.
* Trained a generative model with AiTextGen.
* Creating the interactive web with Streamlit.

### [WhatsApp Conversation Analizer](https://share.streamlit.io/lautaropacella/whatsappanalisis/main/Wpp_Analizer.py)
* Automatic visualization and basic analysis of WhatsApp conversations.

## Practice Projects

### *Data Analysis*

#### [Exploratory analysis on city traffic open data from Corrientes City (in Spanish)](https://nbviewer.jupyter.org/github/lautaropacella/EDA-Tr-nsito-Corrientes/blob/main/Transito_corrientes1.ipynb)

### *Regression Problems*

#### [Predicción de Precio de Venta de Departamentos de Buenos Aires (in Spanish)](https://nbviewer.jupyter.org/github/lautaropacella/Prediccion-Departamentos/blob/master/Imbo-BsAs.ipynb)
* Web Scraping of www.MercadoLibre.com for Appartments data in each neighborhood. 
* Cleaning the data obtained to make it ready for machine learning. 
* Testing different regression algorithms, selecting of the best one on the accuracy score (RandomForestRegressor) with K-Fold Cross-Validation, and using RandomSearchCV to search for hyperparameter tuning.
 * Visualization of the feature importances.
 
### *Classification Problems*
 
#### [Telco Customer Churn](https://nbviewer.jupyter.org/github/lautaropacella/Telco-Customer-Churn/blob/master/telco-customer-churn.ipynb)
* Read data from www.kaggle.com and define the problem to solve.
* Visualization of variables for insights.
* Trying out different classification models. Choosing the best one based on accuracy score (Logistic Regression). Tuning it's parameters with SearchGrid.
* Visualizing and analizyng feature importances.

#### [Predicción de Promociones de una Multinacional](https://nbviewer.jupyter.org/github/lautaropacella/Predicci-n-Promociones/blob/main/predicci%C3%B3n_promoci%C3%B3n.ipynb)
* Defining the problem.
* Visualization and analysis of the data.
* Selecting best classification algorithm and hyperparameter tuning.
* Reporting predictions.

### *Competitions*

#### [Prediction of Buying Intention from a Web Page - from www.datasource.ai](https://www.datasource.ai/es/home/data-science-competitions-for-startups/prediccion-de-la-intencion-de-compra-en-una-pagina-web)
* Finished in 10th Place.
* 
#### [Prediction of Appartment Prices in Argentina and Colombia - from www.datasource.ai](https://www.datasource.ai/es/home/competiciones-en-data-science/prediccion-de-precios-de-apartamentos-en-argentina-y-colombia)
* Finished in 13th Place.

